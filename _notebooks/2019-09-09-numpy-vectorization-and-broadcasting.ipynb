{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization, broadcasting, boolean masking\n",
    "> Numpy, Pytorch, ...\n",
    "\n",
    "- toc: true \n",
    "- hide: false\n",
    "- branch: master\n",
    "- search_exclude: false\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [numpy, pytorch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Unlike compiled languages like C or Fortran, loops in python are quite slow. When I first started using python several years ago, if I had to compute the average over one axis (y) of a 2D function `v(x,y)`, I would do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny = v.shape\n",
    "ave = np.zeros(nx)\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        ave[i] += v[i, j]\n",
    "    \n",
    "ave[i] /= ny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Then I got a little smarter and removed one loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nx):\n",
    "    ave[i] = np.mean(v[i,  n:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "But thanks to **numpy ufuncs** [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/02.03-computation-on-arrays-ufuncs.html), I realized that I do not need any loops at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "ave = np.mean(v, axis=1, keepdims=True) # keep the same dimensions as v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "It turns out a whole lot of operations can be **vectorized** using [numpy ufuncs](https://docs.scipy.org/doc/numpy/reference/ufuncs.html). What is even better is that if you are going to repeat the same operation, you can use `partial` from functools to define a numpy ufunc with defaults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "ave_y = partial(np.mean, axis=1)\n",
    "ave_y(v) # averages over the 2nd axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting \n",
    "\n",
    "Another problem I faced when I first started using python was dealing with arrays with mismatched dimensions. Consider a case where array `x` has shape (10,2) and I want to add another array `y` to it with shape (2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10, 2) # x.shape = (10,2)\n",
    "y = np.array([1, 2]) # y.shape = (2)\n",
    "# x + y won't work\n",
    "x + y[np.newaxis, :] # works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **scikit-learn**: The feature array in scikit-learn API is expected to be 2 dimensional. Let's say you only want to do linear regression only on 1 feature (1D = number of samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "x = np.random.randn(10)\n",
    "y = 3*x + 5 + 0.1*np.random.randn(10)\n",
    "model = Lasso()\n",
    "model.fit(x, y)\n",
    "# Returns ValueError: Expected 2D array, got 1D array...\n",
    "# Reshape your data either using array.reshape(-1, 1) if\n",
    "# your data has a single feature or array.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Scikit-learn throws a helpful error message with a suggested fix: `model.fit(x.reshape(-1,1), y)`. You can also use `x[:, np.newaxis]`.\n",
    "\n",
    "Alternatively, one might want to use two *feature* arrays of dimension 1 in scikit-learn. Scikit-learn expects dimension 2 feature arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "x1 = np.random.randn(10)\n",
    "x2 = np.arange(10)\n",
    "# Efficient way: column_stack\n",
    "X  = np.column_stack((x1, x2))\n",
    "# Long, inefficient way\n",
    "X = np.zeros((x1.shape, 2))\n",
    "X[:, 0] = x1\n",
    "X[:, 1] = x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on broadcasting, see [Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow](https://github.com/ageron/handson-ml2/blob/master/tools_numpy.ipynb) and [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean masking and array dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "x = np.linspace(1, 10, 10)\n",
    "x > 5\n",
    "# array([False, False, False, False, False,  True,  True,  True,  True, True])\n",
    "x[x > 5] # array([ 6.,  7.,  8.,  9., 10.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A conditional statement `x>5` generates a boolean array of the same dimension as the original array. When we use `x[x>5]`, only the values satisfying the conditional statement are returned. In many applications, it is not a problem but if you have code that breaks if the array dimensions don't match anymore, you want to simply multiply the boolean array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x * (x > 5)\n",
    "# array([ 0.,  0.,  0.,  0.,  0.,  6.,  7.,  8.,  9., 10.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xarray**: A lot of these vectorization and broadcasting operations are made easy by [xarray](http://xarray.pydata.org/en/stable/quick-overview.html) where as a bonus, parallelism is included using [dask](https://dask.org/). A good tutorial on the utility of xarray is [here](https://rabernat.github.io/research_computing/xarray.html)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
